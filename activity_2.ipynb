{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXEwV0DJ2KOnXAyYHk1J9O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaniiarR/ai-application-system-hw-week5/blob/main/activity_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j08J_sDwnoBR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU3kR5_coSM2",
        "outputId": "54d0ac94-b36b-4c47-bec4-0908bb734ae8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the learning rates to be experimented\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "\n",
        "for lr in learning_rates:\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(f\"Training model with learning rate: {lr}\")\n",
        "    model.fit(train_images, train_labels, epochs=5, batch_size=32)\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "    print(f\"Test accuracy with learning rate {lr}: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HZOzmnontLz",
        "outputId": "cea3693f-c794-4dea-f0e1-f4e05b491f10"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with learning rate: 0.001\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2568 - accuracy: 0.9267\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1134 - accuracy: 0.9671\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0788 - accuracy: 0.9772\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0594 - accuracy: 0.9815\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0448 - accuracy: 0.9858\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.0755 - accuracy: 0.9766\n",
            "Test accuracy with learning rate 0.001: 0.9765999913215637\n",
            "Training model with learning rate: 0.01\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2426 - accuracy: 0.9278\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1600 - accuracy: 0.9548\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1470 - accuracy: 0.9605\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1323 - accuracy: 0.9658\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1244 - accuracy: 0.9683\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.9619\n",
            "Test accuracy with learning rate 0.01: 0.961899995803833\n",
            "Training model with learning rate: 0.1\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5581 - accuracy: 0.4699\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.6106 - accuracy: 0.4148\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.6491 - accuracy: 0.3966\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.6630 - accuracy: 0.4014\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5847 - accuracy: 0.4210\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 1.5623 - accuracy: 0.4235\n",
            "Test accuracy with learning rate 0.1: 0.4235000014305115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Experiment with Different Batch Sizes\n",
        "# Define the batch sizes to be experimented\n",
        "batch_sizes = [32, 64, 128]\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)  # Using a fixed learning rate for this experiment\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(f\"Training model with batch size: {batch_size}\")\n",
        "    model.fit(train_images, train_labels, epochs=5, batch_size=batch_size)\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "    print(f\"Test accuracy with batch size {batch_size}: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2jxaGxLn26Q",
        "outputId": "e5249f6f-414c-4f1a-ee7e-ecdc8cd874ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with batch size: 32\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2379 - accuracy: 0.9303\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1587 - accuracy: 0.9555\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1374 - accuracy: 0.9627\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1303 - accuracy: 0.9654\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1195 - accuracy: 0.9692\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.1624 - accuracy: 0.9663\n",
            "Test accuracy with batch size 32: 0.9663000106811523\n",
            "Training model with batch size: 64\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2169 - accuracy: 0.9347\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1278 - accuracy: 0.9634\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1103 - accuracy: 0.9685\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1000 - accuracy: 0.9713\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0886 - accuracy: 0.9742\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.1343 - accuracy: 0.9699\n",
            "Test accuracy with batch size 64: 0.9699000120162964\n",
            "Training model with batch size: 128\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2162 - accuracy: 0.9331\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1056 - accuracy: 0.9677\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0893 - accuracy: 0.9726\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0767 - accuracy: 0.9765\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0709 - accuracy: 0.9779\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.1218 - accuracy: 0.9709\n",
            "Test accuracy with batch size 128: 0.9708999991416931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3EoUd-pAozLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Discuss the Trade-offs\n",
        "**Learning Rate:**\n",
        "\n",
        "*Small Learning Rate (e.g., 0.001):* Training will be more stable, but it might be slow, especially in finding the global minimum of the loss function.\n",
        "\n",
        "*Medium Learning Rate (e.g., 0.01):* A balance between stability and speed. It often converges to a good solution without being too slow.\n",
        "\n",
        "*Large Learning Rate (e.g., 0.1):* Training might be faster, but it could overshoot the minimum and fail to converge or converge to a suboptimal solution.\n",
        "\n",
        "**Batch Size:**\n",
        "\n",
        "*Small Batch Size (e.g., 32):* Models converge faster because they are updated more frequently. However, the noise in the parameter updates can cause the model to get stuck in local minima.\n",
        "\n",
        "*Medium Batch Size (e.g., 64):* A good balance between the advantages of small and large batch sizes. It often leads to stable convergence.\n",
        "\n",
        "*Large Batch Size (e.g., 128):* Training is faster as updates are less frequent. However, very large batch sizes can lead to convergence to sharp minimizers and can cause generalization issues."
      ],
      "metadata": {
        "id": "NboYuioBo7le"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rDtVxCk8pFCE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}